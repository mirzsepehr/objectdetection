{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Explained\n",
    "First of all we are going to import the required frameworks and tools that we're going to use. We need fastapi in order to make the program RESTful API, uvicorn in oeder to run the program, torch is used to upload the model and using it properly, and some other stuff which I'm going to explain as we go further!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import (FastAPI, \n",
    "                     File, \n",
    "                     UploadFile, \n",
    "                     Request, \n",
    "                     HTTPException)\n",
    "from fastapi.responses import JSONResponse\n",
    "import torch\n",
    "from PIL import Image\n",
    "import io\n",
    "import uuid\n",
    "import cv2\n",
    "import numpy as np\n",
    "import uvicorn\n",
    "from fastapi.testclient import TestClient\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import platform\n",
    "\n",
    "\n",
    "app = FastAPI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since my OS is Windows, my program will crash on my docker container if don't set these lines of codes. The reason is docker container has its own ways to deal with paths which is different from what you might see in the Windows operating system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/objdetection/app/yolov5')\n",
    "if platform.system() == 'Windows':\n",
    "    pathlib.PosixPath = pathlib.WindowsPath\n",
    "else:\n",
    "    pathlib.WindowsPath = pathlib.PosixPath\n",
    "\n",
    "CELLPHONEMODEL_PATH = Path(str('/objdetection/app/best.pt'))\n",
    "SEATBELTMODEL_PATH = Path(str('/objdetection/app/best_seatbelt.pt'))\n",
    "YOLOV5MODEL = Path('/objdetection/app/yolov5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Then we should write an exception handeler for our code. That's why I have defined some configs as a global variables in my code. \n",
    "</br>\n",
    "</br>\n",
    "- I got the models by torch.hub.load command. I set the device on cpu because the server that is going to run my code, unfortunately doesn't have any GPU available.\n",
    "</br>\n",
    "</br>\n",
    "- running this program on GPU is way faster than CPU. If gpu was available in your server please correct two lines of code below as following:\n",
    "</br>\n",
    "</br>\n",
    "> model_cellphone = torch.hub.load(YOLOV5MODEL, 'custom', path=CELLPHONEMODEL_PATH, force_reload=True, source='local', device='0')\n",
    "> model_seatbelt = torch.hub.load(YOLOV5MODEL, 'custom', path=SEATBELTMODEL_PATH, force_reload=True, source='local', device='0')\n",
    "\n",
    "if there are multiple GPU machines available you can pass multiple variables, for instance:\n",
    "> device = '0, 1, 2'\n",
    "\n",
    "Before running on gpu make sure that you have cuda installed. You can check if the availability of CUDA like this:\n",
    "> 1. open cmd\n",
    "> 2. open the ptrhob interactive shell by writing: python\n",
    "> </br>\n",
    "> </br>\n",
    "> 3. >import torch\n",
    "> 4. >print(torch.cuda.is_available)\n",
    "\n",
    "The output should be True. If it's false then something's going wrong!\n",
    "- Last two lines my code sets the confidence threshold for detecting objects. If the confidence is below this variable the detection result would be false and vice versa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = TestClient(app)\n",
    "IMAGEDIR = \"fastapi-images/\"\n",
    "image_names = []\n",
    "allowed_image_types = [\"image/jpeg\", \"image/png\", \"image/gif\"]\n",
    "\n",
    "\n",
    "#load models from saved '.pt' path \n",
    "torch.hub._validate_not_a_forked_repo=lambda a,b,c: True\n",
    "model_cellphone = torch.hub.load(YOLOV5MODEL, 'custom', path=CELLPHONEMODEL_PATH, force_reload=True, source='local', device='cpu') \n",
    "model_seatbelt = torch.hub.load(YOLOV5MODEL, 'custom', path=SEATBELTMODEL_PATH, force_reload=True, source='local', device='cpu') \n",
    "model_cellphone.conf = 0.25\n",
    "model_seatbelt.conf = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is my exception handeler. There are a few other ways to writing it. you can check it out in the **[fastapi docs](https://devdocs.io/fastapi/)**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class notReceivedException(Exception):\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "@app.exception_handler(notReceivedException)\n",
    "async def notReceived_exception_handler(request: Request, exc:notReceivedException):\n",
    "    return JSONResponse(\n",
    "        status_code=404,\n",
    "        content={\"message\": f\"Oops! {exc.name} didn't receive!\"},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **\"/detect\"** POST Method\n",
    "This method detects both cellphone and seatbelts. \n",
    "- At the beginning of the code I have written some exception handelers to see if the file is received, and if the file is the required type. (\"jpeg\", \"png\", or \"gif\") \n",
    "- Then I read the files and I rotate one of the images. If you'd ask me why I would say that images saved into \"image\" variable upside down! That's the reason behind the 180 degree rotation, nothing more!!\n",
    "- I gave the images to my models! --> results_seatbelt = model_seatbelt(image)\n",
    "</br>\n",
    "</br>\n",
    "The Idea behind the verbose parameter is that I want to be able to return the results in two types! If the verbose is false, then this api will simply return a boolean True or False! However, If you set the query variable (verbose) to true you can get details of your detection. If the detection is \"False\" then you will get an empty list.\n",
    "Something like this:\n",
    "\"\"\"</br>\n",
    "{</br>\n",
    "  \"phone detections\": []</br>\n",
    "}</br>\n",
    "\"\"\"</br>\n",
    "Conversely, if your detection is \"True\", then you will get an dictionary which tells you about the **confidence** of the detection, and the **bounding box** which tells you about the location of the detected object in the image in terms of x and y! it will look like something like this:\n",
    "</br>\n",
    "\"\"\"</br>\n",
    "{</br>\n",
    "  \"phone detections\": [</br>\n",
    "    {</br>\n",
    "      \"class\": \"cellphone\",</br>\n",
    "      \"confidence\": 0.7376633286476135,</br>\n",
    "      \"bbox\": [</br>\n",
    "        70.04457092285156,</br>\n",
    "        53.837162017822266,</br>\n",
    "        130.4330291748047,</br>\n",
    "        104.666748046875</br>\n",
    "      ]</br>\n",
    "    }</br>\n",
    "  ]</br>\n",
    "}</br>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.post(\"/detect\")\n",
    "async def detect_objects(file: UploadFile = File(...), verbose:bool = False):\n",
    "    \"\"\"\n",
    "    Detects both cellphones and seatbelts. \n",
    "    if you set the query parameter 'verbose' to True it will \n",
    "    return in this format rather than true or false:\n",
    "    _____________________________________________________\n",
    "    {   \n",
    "        \"class\":string (cellphone, seatbelt ...) ,\n",
    "        \"confidence\": float (how much confident my model is about the detected object. this parameter is between 0 and 1. 1->totaly confident and 0->not confident at all!),\n",
    "        \"bbox\": [x1, y1, x2, y2] (list of four float parameters that shows the location of the detected object in the image)\n",
    "    }\n",
    "    _____________________________________________________\n",
    "    if more than one object is detected then it will return \n",
    "    some dictionaries that each of them is associated \n",
    "    with one of the detected objects.\n",
    "    In other words, number of returned dictionaries are the total number of detcted objects!\n",
    "    \"\"\"\n",
    "    #manage input:\n",
    "    if not file:\n",
    "        raise notReceived_exception_handler(name = \"file\")\n",
    "    if file.content_type not in allowed_image_types:\n",
    "        raise HTTPException(status_code=400, \n",
    "                            detail=\"Invalid File type. (only jpeg, png or gif are allowed)\"\n",
    "                        )\n",
    "    # detection = False\n",
    "\n",
    "    #read images\n",
    "    image_bytes = await file.read()\n",
    "    image = Image.open(io.BytesIO(image_bytes))\n",
    "    image = image.rotate(180)\n",
    "\n",
    "    #load models\n",
    "    results_seatbelt = model_seatbelt(image)\n",
    "    results_cellphone = model_cellphone(image)\n",
    "    #if verbose is true then we must generate output in a particular format which i have explained above!\n",
    "    if verbose:\n",
    "        #generate file name and save it.\n",
    "        file.filename = f\"{uuid.uuid4()}\"\n",
    "        # image.save(f\"{IMAGEDIR}{file.filename}.jpg\")\n",
    "        with Image.open(f\"{IMAGEDIR}{file.filename}.jpg\") as f:\n",
    "            frame = np.array(f)\n",
    "            #get the location of the detected object in the image:\n",
    "            for box in results_cellphone.xyxy[0]: \n",
    "                if box[5]==0:\n",
    "                    # detection = True\n",
    "                    xB = int(box[2])\n",
    "                    xA = int(box[0])\n",
    "                    yB = int(box[3])\n",
    "                    yA = int(box[1])\n",
    "                    rect = cv2.rectangle(frame, (xA, yA), (xB, yB), (0, 255, 0), 2)\n",
    "                    # rect.save(f\"{IMAGEDIR}{file.filename}_cellphone.jpg\")\n",
    "                    im = Image.fromarray(rect)\n",
    "                    # im.save(f\"{IMAGEDIR}{file.filename}_cellphone.jpg\")\n",
    "                    # image_names.append(f\"{file.filename}_cellphone.jpg\")\n",
    "            for box in results_seatbelt.xyxy[0]: \n",
    "                if box[5]==0:\n",
    "                    xB = int(box[2])\n",
    "                    xA = int(box[0])\n",
    "                    yB = int(box[3])\n",
    "                    yA = int(box[1])\n",
    "                    #draw a rectabgle around the detected object and save it somewhere:\n",
    "                    rect = cv2.rectangle(frame, (xA, yA), (xB, yB), (0, 255, 0), 2)\n",
    "                    im = Image.fromarray(rect)\n",
    "                    # im.save(f\"{IMAGEDIR}{file.filename}_seatbelt.jpg\")\n",
    "            \n",
    "    seatbelt_detections = []\n",
    "    phone_detections = []\n",
    "    for result in results_cellphone.xyxy[0]:\n",
    "        x1, y1, x2, y2, conf, _ = result.tolist()\n",
    "        phone_detections.append({\n",
    "            \"class\": \"cellphone\",\n",
    "            \"confidence\": conf,\n",
    "            \"bbox\": [x1, y1, x2, y2]\n",
    "        })\n",
    "        \n",
    "    for result in results_seatbelt.xyxy[0]:\n",
    "        x1, y1, x2, y2, conf, _ = result.tolist()\n",
    "        seatbelt_detections.append({\n",
    "            \"class\": \"seatbelt\",\n",
    "            \"confidence\": conf,\n",
    "            \"bbox\": [x1, y1, x2, y2]\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"phone detections\": phone_detections if phone_detections and verbose else bool(phone_detections), \n",
    "        \"seatbelt detections\": seatbelt_detections if seatbelt_detections and verbose else bool(seatbelt_detections)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **\"/cellphone\"**  & **\"/seatbelt\"**POST Method\n",
    "These two work exactly the same with the previous one(detect_objects()). The difference is they only detect the objects that has written in their url path. Verbose qyery oarameter works exactly the same as the previous one.</br>\n",
    "</br>\n",
    "**Note**: In all of methods, the default value of verbose is \"False\". It means that our functions will return bool values until you change it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.post(\"/cellphone\")\n",
    "async def detect_cellphone(file: UploadFile = File(...), verbose:bool=False):\n",
    "    \"\"\"\n",
    "    This function merely returns cellphone detection outputs. \n",
    "    The verbose query variable works exactly like previous one. \n",
    "    if verbose is true, then instead of True or False it will return \n",
    "    a dictionary in the following format:\n",
    "    _____________________________________________________\n",
    "    {   \n",
    "        \"class\":\"cellphone\",\n",
    "        \"confidence\": float (how much confident my model is about the detected object. this parameter is between 0 and 1. 1->totaly confident and 0->not confident at all!),\n",
    "        \"bbox\": [x1, y1, x2, y2] (list of four float parameters that shows the location of the detected object in the image which is cellphone in this case!)\n",
    "    }\n",
    "    _____________________________________________________\n",
    "\n",
    "    \"\"\"\n",
    "    if not file:\n",
    "        raise notReceived_exception_handler(name = \"file\")\n",
    "    if file.content_type not in allowed_image_types:\n",
    "        raise HTTPException(status_code=400, \n",
    "                            detail=\"Invalid File type. (only jpeg, png or gif are allowed)\"\n",
    "                        )\n",
    "    image_bytes = await file.read()\n",
    "    image = Image.open(io.BytesIO(image_bytes))\n",
    "    image = image.rotate(180)\n",
    "    results_cellphone = model_cellphone(image)\n",
    "    phone_detections = []\n",
    "    for result in results_cellphone.xyxy[0]:\n",
    "        x1, y1, x2, y2, conf, _ = result.tolist()\n",
    "        phone_detections.append({\n",
    "            \"class\": \"cellphone\",\n",
    "            \"confidence\": conf,\n",
    "            \"bbox\": [x1, y1, x2, y2]\n",
    "        })\n",
    "\n",
    "    return {\"phone detections\": phone_detections if verbose else bool(phone_detections)}\n",
    "\n",
    "\n",
    "@app.post(\"/seatbelt\")\n",
    "async def detect_seatbelt(file:UploadFile=File(...), verbose:bool = False):\n",
    "    \"\"\"\n",
    "    This function merely returns seatbelt detection outputs. \n",
    "    The verbose query variable works exactly like previous one. \n",
    "    if verbose is true, then instead of True or False it will return \n",
    "    a dictionary in the following format:\n",
    "    _____________________________________________________\n",
    "    {   \n",
    "        \"class\":\"seatbelt\",\n",
    "        \"confidence\": float (how much confident my model is about the detected object. this parameter is between 0 and 1. 1->totaly confident and 0->not confident at all!),\n",
    "        \"bbox\": [x1, y1, x2, y2] (list of four float parameters that shows the location of the detected object in the image which is seatbelt in this case!)\n",
    "    }\n",
    "    ______________________________________________________\n",
    "    \"\"\"\n",
    "    if not file:\n",
    "        raise notReceived_exception_handler(name = \"file\")\n",
    "    if file.content_type not in allowed_image_types:\n",
    "        raise HTTPException(status_code=400, \n",
    "                            detail=\"Invalid File type. (only jpeg, png or gif are allowed)\"\n",
    "                        )\n",
    "    image_bytes = await file.read()\n",
    "    image = Image.open(io.BytesIO(image_bytes))\n",
    "    image = image.rotate(180)\n",
    "    results_seatbelt = model_seatbelt(image)\n",
    "    seatbelt_detections = []\n",
    "    for result in results_seatbelt.xyxy[0]:\n",
    "        x1, y1, x2, y2, conf, _ = result.tolist()\n",
    "        seatbelt_detections.append({\n",
    "            \"class\": \"seatbelt\",\n",
    "            \"confidence\": conf,\n",
    "            \"bbox\": [x1, y1, x2, y2]\n",
    "        })\n",
    "        \n",
    "    return {\"phone detections\": seatbelt_detections if verbose else bool(seatbelt_detections)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can ignore the frollowing lines because we are not running this program directly with python command. As you can see in the dockerfile we run this program with: </br>\n",
    "CMD [ \"uvicorn\", \"app.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"5000\"]</br>\n",
    "</br>\n",
    "</br>\n",
    "**Important Note**: when you run the program with docker it will say you something like this:</br>\n",
    "> Uvicorn running on http://0.0.0.0:5000 (Press CTRL+C to quit)</br>\n",
    "\n",
    "\n",
    "If you go to your browser and enter the http://0.0.0.0:5000 url, the page will not be loaded. Instead enter http://127.0.0.1:5000 or **localhost:5000**. idk why it works this way but this is what it is!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "   uvicorn.run(app, host=\"127.0.0.1\", port=8000)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
